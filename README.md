# DATA 606 - Capstone Project

**Ujjwal**

**Data Science Department**

**University of Maryland, Baltimore County**

> ***UMBC Global Ambassador***

> ***Grduate Grader (Data Science)***

## About me
I am a passionate and a motivated professional with sheer interest in Data Science and Machine learning. Proficient in data cleaning and transformation, I am adept at conducting statistical analysis to derive data-driven insights and develop machine learning models. I am eagerly looking to join an organization where I can add value and make notable impact through my competent problem solving skills.

## Project Draft Proposal
1. What is your issue of interest (provide sufficient background)?
   - I want to work on the analysis of audio data to develop machine learning models for either sentiment analysis, emotion detection or any state of art application.

2. Why is this issue important to you and/or to others?
   - Analysis of audio data has a lot of challenges and potential along with real world applications.
   - I have already worked on image processing and natural language processing and I feel that working on audio data will equip me to work on multimodal AI tasks. 
   - With the rise of audio assistants like Alexa and Siri, this field seems really promising to me.

3. What questions do you have in mind and would like to answer?
   - I want to understand how the variation in audio data can be normalized to develop various audio assisted applications.
   - I want to understand if there is significant difference in the audio signals based on gender, dialect, accent etc.

4. Where do you get the data to analyze and help answer your questions (credibility of source, quality of data, size of data, attributest of data etc.)?
   - There are a lot of amazing sources available for audio, audio-visual and audio-visual text data.
   - I found the following sources most useful:
   - https://github.com/philipperemy/timit/blob/master/README.md , https://www.kaggle.com/mfekadu/darpa-timit-acousticphonetic-continuous-speech?select=PROMPTS.TXT
   - https://paperswithcode.com/dataset/vctk
   - https://paperswithcode.com/dataset/common-voice  

5. What will be your unit of analysis (for example, patient, organization, or country)? Roughly how many units (observations) do you expect?
   - Unit of analysis will be audio files and the associated attributes like male/female speaker, dialect, emotion portrayed etc.
   - I have come across datasets varying from 500 MBs to 70 GBs. I am trying to narrow down the part of my analysis to avoid any unnecessary compute intensive tasks.

6. What variable/measures do you plan to use in your analysis (variables should be tied to the question in #3)?
   - For initial analysis purposes I want to observe the difference in the waveform of audios based on gender, dialect, accent, etc.
   - For modeling purpose, I want to observe how current models perform for each individual class. For example, are the current ML models more confident in predicting male voices then female voices, or which dialect is easily recognized and which isn't, etc.

7. What kind of techniques/models do you plan to use (for example, clustering, NLP, ARIMA, etc.)?
   - I plan to use NLP and Deep Learning models for classification and prediction purposes.

8. How do you plan to develop/apply ML and how you evaluate/compare the performance of the models?
   - Initially I aim to compare them on the basis of accuracy score.

9. What outcomes do you intend to achieve (better understanding of the problems, tools to help solve problems, predictive analytics with practicle applications, etc.)?
   - I intend to develop a state of the art multimodal emotion detector or sentiment detector which can leverage all 3 types of data i.e. audio, visual and text.
